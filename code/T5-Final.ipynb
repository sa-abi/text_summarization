{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 15 08:30:17 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Quadro RTX 8000                On  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0             ERR! / 250W |      0MiB / 46080MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/aa9798'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m20.2.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting regex (from sacrebleu)\n",
      "  Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting numpy>=1.17 (from sacrebleu)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Using cached lxml-4.9.3-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Using cached sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached lxml-4.9.3-cp38-cp38-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tabulate, regex, portalocker, numpy, lxml, colorama, sacrebleu\n",
      "Successfully installed colorama-0.4.6 lxml-4.9.3 numpy-1.24.4 portalocker-2.8.2 regex-2023.10.3 sacrebleu-2.4.0 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m20.2.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting Rouge\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting six (from Rouge)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: six, Rouge\n",
      "Successfully installed Rouge-1.0.1 six-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m20.2.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 nltk\n",
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 sacrebleu\n",
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m20.2.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m20.2.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 transformers wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp38-cp38-linux_x86_64.whl (2325.9 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp38-cp38-linux_x86_64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting requests (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting charset-normalizer<3,>=2 (from requests->torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/share/apps/python/3.8.6/intel/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 certifi-2022.12.7 charset-normalizer-2.1.1 filelock-3.9.0 fsspec-2023.4.0 idna-3.4 jinja2-3.1.2 mpmath-1.3.0 networkx-3.0 numpy-1.24.1 pillow-9.3.0 requests-2.28.1 sympy-1.12 torch-2.1.2+cu118 torchaudio-2.1.2+cu118 torchvision-0.16.2+cu118 triton-2.1.0 typing-extensions-4.4.0 urllib3-1.26.13\n"
     ]
    }
   ],
   "source": [
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade --target=/scratch/aa9798 scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import io\n",
    "\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "def compute_bleu(reference_corpus,\n",
    "                 translation_corpus,\n",
    "                 max_order=1,\n",
    "                 smooth=False):\n",
    "    def _get_ngrams(segment, max_order):\n",
    "        ngram_counts = collections.Counter()\n",
    "        for order in range(1, max_order + 1):\n",
    "            for i in range(0, len(segment) - order + 1):\n",
    "                ngram = tuple(segment[i:i + order])\n",
    "                ngram_counts[ngram] += 1\n",
    "        return ngram_counts\n",
    "\n",
    "    matches_by_order = [0] * max_order\n",
    "    possible_matches_by_order = [0] * max_order\n",
    "    reference_length = 0\n",
    "    translation_length = 0\n",
    "    for (references, translation) in zip(reference_corpus, translation_corpus):\n",
    "        reference_length += min(len(r) for r in references)\n",
    "        translation_length += len(translation)\n",
    "\n",
    "        merged_ref_ngram_counts = collections.Counter()\n",
    "        for reference in references:\n",
    "            merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "        translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "        overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "        for ngram in overlap:\n",
    "            matches_by_order[len(ngram) - 1] += overlap[ngram]\n",
    "        for order in range(1, max_order + 1):\n",
    "            possible_matches = len(translation) - order + 1\n",
    "            if possible_matches > 0:\n",
    "                possible_matches_by_order[order - 1] += possible_matches\n",
    "\n",
    "    precisions = [0] * max_order\n",
    "    for i in range(0, max_order):\n",
    "        if smooth:\n",
    "            precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "                             (possible_matches_by_order[i] + 1.))\n",
    "        else:\n",
    "            if possible_matches_by_order[i] > 0:\n",
    "                precisions[i] = (float(matches_by_order[i]) /\n",
    "                                 possible_matches_by_order[i])\n",
    "            else:\n",
    "                precisions[i] = 0.0\n",
    "\n",
    "    if min(precisions) > 0:\n",
    "        p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "        geo_mean = math.exp(p_log_sum)\n",
    "    else:\n",
    "        geo_mean = 0\n",
    "\n",
    "    ratio = float(translation_length) / reference_length\n",
    "\n",
    "    if ratio > 1.0:\n",
    "        bp = 1.\n",
    "    else:\n",
    "        bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "    bleu = geo_mean * bp\n",
    "\n",
    "    return bleu\n",
    "\n",
    "def compute_rouge(reference_corpus, translation_corpus):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(translation_corpus, reference_corpus, avg=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.text\n",
    "        self.ctext = self.data.ctext\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long),\n",
    "            'source_mask': source_mask.to(dtype=torch.long),\n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        labels = y[:, 1:].clone().detach()\n",
    "        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        if _%10 == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        if _%500==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(epoch, tokenizer, model, device, train_loader, val_loader, optimizer):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "        # Training code (as in your existing train function)\n",
    "        y = data['target_ids'].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        labels = y[:, 1:].clone().detach()\n",
    "        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, decoder_input_ids=y_ids, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        if _ % 10 == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        if _ % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, Training Loss: {loss.item()}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Print and log training loss\n",
    "    print(f'Epoch: {epoch}, completed Training Loss: {avg_train_loss}')\n",
    "    wandb.log({\"Train Loss\": avg_train_loss})\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, val_data in enumerate(val_loader, 0):\n",
    "            # Validation code (similar to your existing validate function)\n",
    "            # Make sure to accumulate the validation loss\n",
    "            val_y = val_data['target_ids'].to(device, dtype=torch.long)\n",
    "            val_y_ids = val_y[:, :-1].contiguous()\n",
    "            val_labels = val_y[:, 1:].clone().detach()\n",
    "            val_labels[val_y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "            val_ids = val_data['source_ids'].to(device, dtype=torch.long)\n",
    "            val_mask = val_data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            val_outputs = model(input_ids=val_ids, attention_mask=val_mask, decoder_input_ids=val_y_ids, labels=val_labels)\n",
    "            val_loss = val_outputs[0]\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    # Calculate average validation loss for the epoch\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Print and log validation loss\n",
    "    print(f'Epoch: {epoch}, completed Validation Loss: {avg_val_loss}')\n",
    "    wandb.log({\"Validation Loss\": avg_val_loss})\n",
    "\n",
    "    return avg_train_loss, avg_val_loss  # You can return other metrics if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    total_iterations = len(loader)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype=torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                max_length=150,\n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5,\n",
    "                length_penalty=1.0,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in y]\n",
    "\n",
    "            if _ % 10 == 0:\n",
    "                print(_)\n",
    "\n",
    "            if _ % 100 == 0:\n",
    "                print(f'Completed {_} iterations')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "\n",
    "    return predictions, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to read files and create DataFrame\n",
    "def create_dataframe(root_folder):\n",
    "    data = {'articles': [], 'summaries': [], 'category': [], 'file_name': []}\n",
    "\n",
    "    # Loop through the subfolders\n",
    "    for category in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "        # Path to News Articles and Summaries folders\n",
    "        articles_path = os.path.join(root_folder, 'News Articles', category)\n",
    "        summaries_path = os.path.join(root_folder, 'Summaries', category)\n",
    "\n",
    "        # Get the list of files in the category\n",
    "        files_list = [file_name for file_name in os.listdir(articles_path) if file_name.endswith('.txt')]\n",
    "\n",
    "        # Loop through the files in each subfolder with a progress bar\n",
    "        for file_name in tqdm(files_list, desc=f'Processing {category}'):\n",
    "            # Read article content\n",
    "            with open(os.path.join(articles_path, file_name), 'r', encoding='utf-8', errors='replace') as article_file:\n",
    "                article_content = article_file.read()\n",
    "\n",
    "            # Read summary content\n",
    "            summary_file_path = os.path.join(summaries_path, file_name)\n",
    "            with open(summary_file_path, 'r', encoding='utf-8') as summary_file:\n",
    "                summary_content = summary_file.read()\n",
    "\n",
    "            # Append data to dictionary\n",
    "            data['articles'].append(article_content)\n",
    "            data['summaries'].append(summary_content)\n",
    "            data['category'].append(category)\n",
    "            data['file_name'].append(file_name)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'path_to_your_folder' with the actual path to your 'BBC News Summary' folder\n",
    "df = create_dataframe('/scratch/aa9798/news')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'articles': 'text', 'summaries': 'ctext'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum length of text in 'main_text' column:\", df['text'].apply(len).max())\n",
    "print(\"Maximum length of text in 'main_text' column:\", df['ctext'].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"transformers_tutorials_summarization\")\n",
    "config = wandb.config\n",
    "config.TRAIN_BATCH_SIZE = 1    # input batch size for training (default: 64)\n",
    "config.VALID_BATCH_SIZE = 1    # input batch size for testing (default: 1000)\n",
    "config.TRAIN_EPOCHS = 10       # number of epochs to train (default: 10)\n",
    "config.VAL_EPOCHS = 1\n",
    "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
    "config.SEED = 42               # random seed (default: 42)\n",
    "config.MAX_LEN = 4000\n",
    "config.SUMMARY_LEN = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(config.SEED) # pytorch random seed\n",
    "np.random.seed(config.SEED) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "validation_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "# Split into train and temp sets\n",
    "train_dataset, temp_dataset = train_test_split(df, test_size=1 - train_size, random_state=config.SEED)\n",
    "\n",
    "# Split the temp set into validation and test sets\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=test_size/(validation_size + test_size), random_state=config.SEED)\n",
    "\n",
    "# Resetting indices for all datasets\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "val_dataset = val_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"VAL Dataset: {}\".format(val_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET T5 PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "test_set = CustomDataset(test_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': config.VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': config.VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(val_set, **val_params)\n",
    "test_loader = DataLoader(test_set, **val_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN T5 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Fine-Tuning for the model on our dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/aa9798/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 12.617023468017578\n",
      "Epoch: 0, Training Loss: 4.678836822509766\n",
      "Epoch: 0, Training Loss: 5.22426700592041\n",
      "Epoch: 0, Training Loss: 3.174185276031494\n",
      "Epoch: 0, Training Loss: 3.4368274211883545\n",
      "Epoch: 0, Training Loss: 2.740471363067627\n",
      "Epoch: 0, Training Loss: 3.059037446975708\n",
      "Epoch: 0, Training Loss: 2.3849050998687744\n",
      "Epoch: 0, Training Loss: 2.181574821472168\n",
      "Epoch: 0, Training Loss: 2.767366647720337\n",
      "Epoch: 0, Training Loss: 2.5764753818511963\n",
      "Epoch: 0, Training Loss: 2.4283106327056885\n",
      "Epoch: 0, Training Loss: 2.538130521774292\n",
      "Epoch: 0, Training Loss: 2.8266284465789795\n",
      "Epoch: 0, Training Loss: 2.524367332458496\n",
      "Epoch: 0, Training Loss: 3.127093553543091\n",
      "Epoch: 0, Training Loss: 2.474076509475708\n",
      "Epoch: 0, Training Loss: 2.9501917362213135\n",
      "Epoch: 0, Training Loss: 2.5646896362304688\n",
      "Epoch: 0, Training Loss: 2.4305949211120605\n",
      "Epoch: 0, Training Loss: 2.8118746280670166\n",
      "Epoch: 0, Training Loss: 2.3225185871124268\n",
      "Epoch: 0, Training Loss: 2.2575595378875732\n",
      "Epoch: 0, Training Loss: 2.385577440261841\n",
      "Epoch: 0, Training Loss: 2.137881278991699\n",
      "Epoch: 0, Training Loss: 2.5106475353240967\n",
      "Epoch: 0, Training Loss: 2.5058112144470215\n",
      "Epoch: 0, Training Loss: 2.2465827465057373\n",
      "Epoch: 0, Training Loss: 2.355177164077759\n",
      "Epoch: 0, Training Loss: 2.1870172023773193\n",
      "Epoch: 0, Training Loss: 2.248870372772217\n",
      "Epoch: 0, Training Loss: 2.44065523147583\n",
      "Epoch: 0, Training Loss: 2.8902196884155273\n",
      "Epoch: 0, Training Loss: 2.288890838623047\n",
      "Epoch: 0, Training Loss: 2.4732205867767334\n",
      "Epoch: 0, Training Loss: 2.3110902309417725\n",
      "Epoch: 0, Training Loss: 2.32211971282959\n",
      "Epoch: 0, Training Loss: 1.8340774774551392\n",
      "Epoch: 0, Training Loss: 2.825910806655884\n",
      "Epoch: 0, Training Loss: 1.7349919080734253\n",
      "Epoch: 0, Training Loss: 2.601276159286499\n",
      "Epoch: 0, Training Loss: 2.212928533554077\n",
      "Epoch: 0, Training Loss: 2.3968288898468018\n",
      "Epoch: 0, Training Loss: 2.3687140941619873\n",
      "Epoch: 0, Training Loss: 2.56992244720459\n",
      "Epoch: 0, Training Loss: 2.863072156906128\n",
      "Epoch: 0, Training Loss: 2.2940096855163574\n",
      "Epoch: 0, Training Loss: 2.5202414989471436\n",
      "Epoch: 0, Training Loss: 1.7213420867919922\n",
      "Epoch: 0, Training Loss: 2.4645447731018066\n",
      "Epoch: 0, Training Loss: 2.1817030906677246\n",
      "Epoch: 0, Training Loss: 2.224236488342285\n",
      "Epoch: 0, Training Loss: 2.507335901260376\n",
      "Epoch: 0, Training Loss: 2.2119483947753906\n",
      "Epoch: 0, Training Loss: 2.200324058532715\n",
      "Epoch: 0, Training Loss: 2.067166566848755\n",
      "Epoch: 0, Training Loss: 2.463425636291504\n",
      "Epoch: 0, Training Loss: 2.0832669734954834\n",
      "Epoch: 0, Training Loss: 2.025106191635132\n",
      "Epoch: 0, Training Loss: 2.2643842697143555\n",
      "Epoch: 0, Training Loss: 2.7474606037139893\n",
      "Epoch: 0, Training Loss: 2.7490546703338623\n",
      "Epoch: 0, Training Loss: 1.9593263864517212\n",
      "Epoch: 0, Training Loss: 2.2657816410064697\n",
      "Epoch: 0, Training Loss: 2.296182870864868\n",
      "Epoch: 0, Training Loss: 2.310748338699341\n",
      "Epoch: 0, Training Loss: 2.4340760707855225\n",
      "Epoch: 0, Training Loss: 2.292348623275757\n",
      "Epoch: 0, Training Loss: 2.3795692920684814\n",
      "Epoch: 0, Training Loss: 1.9426283836364746\n",
      "Epoch: 0, Training Loss: 2.32100772857666\n",
      "Epoch: 0, Training Loss: 2.1532094478607178\n",
      "Epoch: 0, Training Loss: 2.421496629714966\n",
      "Epoch: 0, Training Loss: 1.88316810131073\n",
      "Epoch: 0, Training Loss: 2.7223961353302\n",
      "Epoch: 0, Training Loss: 2.3885414600372314\n",
      "Epoch: 0, Training Loss: 2.1601507663726807\n",
      "Epoch: 0, Training Loss: 2.2083022594451904\n",
      "Epoch: 0, Training Loss: 1.979161262512207\n",
      "Epoch: 0, Training Loss: 2.6202712059020996\n",
      "Epoch: 0, Training Loss: 2.4567360877990723\n",
      "Epoch: 0, Training Loss: 2.6939117908477783\n",
      "Epoch: 0, Training Loss: 1.8462055921554565\n",
      "Epoch: 0, Training Loss: 2.2119648456573486\n",
      "Epoch: 0, Training Loss: 2.2075586318969727\n",
      "Epoch: 0, Training Loss: 2.0047075748443604\n",
      "Epoch: 0, Training Loss: 2.208226442337036\n",
      "Epoch: 0, Training Loss: 2.1539101600646973\n",
      "Epoch: 0, Training Loss: 2.5562386512756348\n",
      "Epoch: 0, Training Loss: 2.252734899520874\n",
      "Epoch: 0, Training Loss: 2.256615400314331\n",
      "Epoch: 0, Training Loss: 2.0021884441375732\n",
      "Epoch: 0, Training Loss: 2.2092840671539307\n",
      "Epoch: 0, Training Loss: 1.9733837842941284\n",
      "Epoch: 0, Training Loss: 2.092362880706787\n",
      "Epoch: 0, Training Loss: 2.273050546646118\n",
      "Epoch: 0, Training Loss: 1.9598246812820435\n",
      "Epoch: 0, Training Loss: 2.0393354892730713\n",
      "Epoch: 0, Training Loss: 2.089115619659424\n",
      "Epoch: 0, Training Loss: 1.957394003868103\n",
      "Epoch: 0, Training Loss: 2.0705504417419434\n",
      "Epoch: 0, Training Loss: 2.310696601867676\n",
      "Epoch: 0, Training Loss: 2.4569828510284424\n",
      "Epoch: 0, Training Loss: 1.9143540859222412\n",
      "Epoch: 0, Training Loss: 2.1303162574768066\n",
      "Epoch: 0, Training Loss: 2.123323678970337\n",
      "Epoch: 0, Training Loss: 2.0916554927825928\n",
      "Epoch: 0, Training Loss: 2.4960381984710693\n",
      "Epoch: 0, Training Loss: 2.0010998249053955\n",
      "Epoch: 0, Training Loss: 2.3775174617767334\n",
      "Epoch: 0, Training Loss: 2.029982566833496\n",
      "Epoch: 0, Training Loss: 2.3339061737060547\n",
      "Epoch: 0, Training Loss: 1.9709322452545166\n",
      "Epoch: 0, Training Loss: 1.978315830230713\n",
      "Epoch: 0, Training Loss: 2.223975896835327\n",
      "Epoch: 0, Training Loss: 2.8495328426361084\n",
      "Epoch: 0, Training Loss: 2.0901095867156982\n",
      "Epoch: 0, Training Loss: 1.9932080507278442\n",
      "Epoch: 0, Training Loss: 2.0793514251708984\n",
      "Epoch: 0, Training Loss: 2.43609881401062\n",
      "Epoch: 0, Training Loss: 2.0108656883239746\n",
      "Epoch: 0, Training Loss: 1.9888379573822021\n",
      "Epoch: 0, Training Loss: 2.0358829498291016\n",
      "Epoch: 0, Training Loss: 2.1963679790496826\n",
      "Epoch: 0, Training Loss: 1.9540051221847534\n",
      "Epoch: 0, Training Loss: 1.7334604263305664\n",
      "Epoch: 0, Training Loss: 2.1431682109832764\n",
      "Epoch: 0, Training Loss: 1.8910380601882935\n",
      "Epoch: 0, Training Loss: 2.215559959411621\n",
      "Epoch: 0, Training Loss: 2.084580183029175\n",
      "Epoch: 0, Training Loss: 1.9584968090057373\n",
      "Epoch: 0, Training Loss: 2.6519711017608643\n",
      "Epoch: 0, Training Loss: 1.8791744709014893\n",
      "Epoch: 0, Training Loss: 2.1002862453460693\n",
      "Epoch: 0, completed Training Loss: 2.3931643913747664\n",
      "Epoch: 0, completed Validation Loss: 1.9892666310406804\n",
      "Epoch: 1 | Train Loss: 2.3931643913747664 | Val Loss: 1.9892666310406804\n",
      "Evaluating on the validation dataset...\n",
      "0\n",
      "Completed 0 iterations\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "Completed 100 iterations\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "Completed 200 iterations\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "Completed 300 iterations\n",
      "310\n",
      "320\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# Define the T5 model and move it to the appropriate device\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Set up optimizer and log the model with wandb\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config.LEARNING_RATE)\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# Start fine-tuning loop\n",
    "print('Initiating Fine-Tuning for the model on our dataset')\n",
    "for epoch in range(config.TRAIN_EPOCHS):\n",
    "    # Train and validate the model for each epoch\n",
    "    train_loss, val_loss = train_and_validate(epoch, tokenizer, model, device, training_loader, val_loader, optimizer)\n",
    "    \n",
    "    # Append losses to lists and print the train loss for the epoch\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print('Epoch:', epoch + 1, '| Train Loss:', train_loss, '| Val Loss:', val_loss)\n",
    "    print('Evaluating on the validation dataset...')\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    rouge_scores = compute_rouge(actuals, predictions)\n",
    "\n",
    "    # Print Rouge scores\n",
    "    print('Epoch:', epoch + 1, '| Rouge-1:', round(rouge_scores['rouge-1']['f'], 4))\n",
    "    print('Epoch:', epoch + 1, '| Rouge-2:', round(rouge_scores['rouge-2']['f'], 4))\n",
    "    print('Epoch:', epoch + 1, '| Rouge-L:', round(rouge_scores['rouge-l']['f'], 4))\n",
    "    # Assuming you have a function to compute BLEU\n",
    "    bleu_score = compute_bleu(actuals, predictions)\n",
    "    print('Epoch:', epoch + 1, '| BLEU:', round(bleu_score, 4))\n",
    "    \n",
    "\n",
    "save_directory = \"/scratch/aa9798/best_model\"\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Optionally, save the tokenizer as well if needed\n",
    "model_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model_tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "# Print a message indicating the start of summary generation\n",
    "print('Now generating summaries on our fine-tuned model for the validation dataset and saving it in a dataframe')\n",
    "\n",
    "# Start validation loop for generating summaries\n",
    "for epoch in range(config.VAL_EPOCHS):\n",
    "    # Validate the model and get predictions and actuals\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, test_loader)\n",
    "    \n",
    "    # Create a dataframe with generated and actual text, and print a message\n",
    "    final_df = pd.DataFrame({'Generated Text': predictions, 'Actual Text': actuals})\n",
    "    print('Output Files generated for review')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/scratch/aa9798/best_model\"\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Optionally, save the tokenizer as well if needed\n",
    "model_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model_tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Replace \"/path/to/save/model\" with the actual directory where you saved your model\n",
    "saved_model_directory = \"/scratch/aa9798/best_model\"\n",
    "\n",
    "# Load the model\n",
    "model = T5ForConditionalGeneration.from_pretrained(saved_model_directory)\n",
    "\n",
    "# If you also saved the tokenizer during training, load it as well\n",
    "tokenizer = T5Tokenizer.from_pretrained(saved_model_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN VAL LOSS CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data (replace these lists with your actual data)\n",
    "epochs = range(1, len(train_losses[:3]) + 1)\n",
    "\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.plot(epochs, train_losses[:3], label='Training Loss', marker='o')\n",
    "# Plotting the validation loss\n",
    "plt.plot(epochs, val_losses[:3], label='Validation Loss', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION - COMPUTE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = compute_rouge(actuals, predictions)\n",
    "model = model.to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "\n",
    "\n",
    "\n",
    "# Print Rouge scores\n",
    "print('Epoch:', epoch + 1, '| Rouge-1:', round(rouge_scores['rouge-1']['f'], 4))\n",
    "print('Epoch:', epoch + 1, '| Rouge-2:', round(rouge_scores['rouge-2']['f'], 4))\n",
    "print('Epoch:', epoch + 1, '| Rouge-L:', round(rouge_scores['rouge-l']['f'], 4))\n",
    "# Assuming you have a function to compute BLEU\n",
    "bleu_score = compute_bleu(actuals, predictions)\n",
    "print('Epoch:', epoch + 1, '| BLEU:', round(bleu_score, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config.VAL_EPOCHS):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, test_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "    print('Output Files generated for review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('/scratch/aa9798/final_df.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
